{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python385jvsc74a57bd05d53690f28159cd40163a87cb1b2cd29275eec4a2395cb3a10ed2b14e07c9013",
   "display_name": "Python 3.8.5 64-bit ('mlenv': conda)"
  },
  "metadata": {
   "interpreter": {
    "hash": "f1c45f18e9d77bf9f276de58c89a7652989b8a06c102bd2dbfc4bda9f8804f24"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# \n",
    "\n",
    "## Deep Reinforced Learning for Cart-Pole Problem\n",
    "\n",
    "Deep reinforced learning is used for stabiliaztion of cart-pole."
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from time import sleep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# make environment of cart-pole, \n",
    "env = gym.make('CartPole-v0')\n",
    "# termination condition of simulation for pole angle and pole velocity\n",
    "isterminate = lambda pole_angle, pole_velo: abs(pole_angle) <= 10 and abs(pole_velo) <= 3\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "car_x: 0.024\tcar_v: 0.209\tpole_ang:           0.045\tpole_v: -0.288\treward: 1.0\n",
      "car_x: 0.028\tcar_v: 0.403\tpole_ang:           0.039\tpole_v: -0.566\treward: 1.0\n",
      "car_x: 0.036\tcar_v: 0.598\tpole_ang:           0.028\tpole_v: -0.846\treward: 1.0\n",
      "car_x: 0.048\tcar_v: 0.792\tpole_ang:           0.011\tpole_v: -1.130\treward: 1.0\n",
      "car_x: 0.064\tcar_v: 0.987\tpole_ang:           -0.012\tpole_v: -1.420\treward: 1.0\n",
      "car_x: 0.084\tcar_v: 1.183\tpole_ang:           -0.040\tpole_v: -1.716\treward: 1.0\n",
      "car_x: 0.107\tcar_v: 1.378\tpole_ang:           -0.075\tpole_v: -2.021\treward: 1.0\n",
      "car_x: 0.135\tcar_v: 1.574\tpole_ang:           -0.115\tpole_v: -2.336\treward: 1.0\n",
      "car_x: 0.166\tcar_v: 1.770\tpole_ang:           -0.162\tpole_v: -2.662\treward: 1.0\n",
      "car_x: 0.202\tcar_v: 1.966\tpole_ang:           -0.215\tpole_v: -2.999\treward: 1.0\n",
      "car_x: 0.241\tcar_v: 2.162\tpole_ang:           -0.275\tpole_v: -3.348\treward: 0.0\n",
      "Terminate\n",
      "/Applications/anaconda3/envs/mlenv/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: You are calling 'step()' even though this environment has already returned done = True. You should always call 'reset()' once you receive 'done = True' -- any further steps are undefined behavior.\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "# termination flag \n",
    "terminate = True \n",
    "env.reset()\n",
    "while terminate:\n",
    "    env.render()\n",
    "    observ, reward, done, info = env.step(1)\n",
    "    \n",
    "    sleep(0.1)\n",
    "\n",
    "    pole_angle, pole_veloc = observ[2:] \n",
    "    terminate = isterminate(pole_angle, pole_veloc)\n",
    "    print(f'car_x: {observ[0]:.3f}\\tcar_v: {observ[1]:.3f}\\tpole_ang: \\\n",
    "          {observ[2]:.3f}\\tpole_v: {observ[3]:.3f}\\treward: {reward}')\n",
    "print('Terminate')\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  }
 ]
}